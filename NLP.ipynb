{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize # For tokenization\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer # For lemmatization\n",
    "from nltk.tag import pos_tag # For POS tagging\n",
    "from nltk.corpus import cmudict # For pronunciation\n",
    "import spacy # For syntactic parsing\n",
    "from spacy import displacy\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F', 'R', 'EH1', 'N', 'D']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CMU Pronouncing Dictionary\n",
    "pronouncing_dict = cmudict.dict()\n",
    "\n",
    "# Function to get pronunciation using CMU Pronouncing Dictionary\n",
    "def get_pronunciation(words):\n",
    "    try:\n",
    "        return pronouncing_dict[word.lower()][0]  # Returning the first pronunciation variant\n",
    "    except KeyError:\n",
    "        return [\"No pronunciation found\"]\n",
    "        \n",
    "word = \"friend\"\n",
    "\n",
    "get_pronunciation(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pronunciation variants can significantly impact speech recognition or synthesis systems in several ways:\n",
    "- Accent Variations: Different regions and speakers may pronounce words differently, leading to variations in pronunciation variants. Speech recognition systems need to be robust enough to recognize and interpret various accents accurately.\n",
    "- Homophones: Words that sound the same but have different meanings (homophones) may have the same pronunciation variants. This ambiguity can introduce challenges for speech recognition systems in accurately understanding the intended word based on context.\n",
    "- Ambiguous Pronunciations: Some words may have multiple valid pronunciation variants, leading to ambiguity in interpretation. Speech recognition systems need to handle such cases by considering contextual cues to determine the correct pronunciation.\n",
    "- Error Handling: In cases where a word is not found in the pronunciation dictionary, speech recognition systems may need to fallback to alternative strategies, such as spell correction or context-based prediction, to accurately transcribe speech.\n",
    "Overall, understanding and effectively handling pronunciation variants are essential for robust and accurate speech recognition and synthesis systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming:\n",
      "running: run\n",
      "ran: ran\n",
      "runs: run\n",
      "leaves: leav\n",
      "left: left\n",
      "leftover: leftov\n",
      "\n",
      "Lemmatization:\n",
      "running: running\n",
      "ran: ran\n",
      "runs: run\n",
      "leaves: leaf\n",
      "left: left\n",
      "leftover: leftover\n"
     ]
    }
   ],
   "source": [
    "tokens = [\"running\", \"ran\", \"runs\", \"leaves\", \"left\", \"leftover\"]\n",
    "\n",
    "# Stem word\n",
    "def stem_word(word):\n",
    "    porter = PorterStemmer()\n",
    "    return porter.stem(word)\n",
    "# Lemmatize word\n",
    "def lemmatize_word(word):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return lemmatizer.lemmatize(word)\n",
    "\n",
    "print(\"Stemming:\")\n",
    "for token in tokens:\n",
    "    stemmed_token = stem_word(token)\n",
    "    print(f\"{token}: {stemmed_token}\")\n",
    "\n",
    "print(\"\\nLemmatization:\")\n",
    "for token in tokens:\n",
    "    lemmatized_token = lemmatize_word(token)\n",
    "    print(f\"{token}: {lemmatized_token}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison:\n",
    "- Stemming: Stemming removes suffixes from words to obtain the root or base form. For example, \"running\", \"ran\", and \"runs\" all stem to \"run\".\n",
    "- Lemmatization: Lemmatization considers the context of the word and aims to return the base or dictionary form (lemma). For example, \"running\" lemmatizes to \"running\", \"ran\" to \"run\", and \"runs\" to \"run\".\n",
    "\n",
    "Preferred Scenarios:\n",
    "- Stemming is generally faster and simpler than lemmatization, making it suitable for applications where speed is crucial, such as information retrieval or text classification.\n",
    "- Lemmatization produces more accurate results by considering the context of words, which is important for tasks requiring precision, such as language understanding or sentiment analysis.\n",
    "- Stemming may be preferred in scenarios where the goal is to reduce words to their base form for indexing or similarity calculations, while lemmatization may be preferred when maintaining the grammatical integrity and semantics of words is essential.\n",
    "- In applications where the distinction between different forms of words (e.g., verb tense or pluralization) is important, lemmatization is usually preferred over stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Adjective-Noun Pairs:\n",
      "('same', 'time'): 94\n",
      "('last', 'year'): 68\n",
      "('first', 'time'): 67\n",
      "('other', 'hand'): 60\n",
      "('fiscal', 'year'): 57\n",
      "('last', 'night'): 56\n",
      "('high', 'school'): 54\n",
      "('old', 'man'): 52\n",
      "('few', 'years'): 49\n",
      "('young', 'man'): 47\n",
      "\n",
      "Top Noun-Adjective Pairs:\n",
      "('years', 'old'): 32\n",
      "('nothing', 'more'): 16\n",
      "('feet', 'high'): 11\n",
      "('hearing', \"officer's\"): 8\n",
      "('years', 'older'): 7\n",
      "('electron', 'optical'): 6\n",
      "('feet', 'tall'): 5\n",
      "('feet', 'long'): 5\n",
      "('something', 'less'): 5\n",
      "('body', 'weight'): 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function for Context Analysis\n",
    "def find_common_pos_context(corpus):\n",
    "    adj_noun_pairs = {}\n",
    "    noun_adj_pairs = {}\n",
    "\n",
    "    # Iterate over sentences in the corpus\n",
    "    for sentence in corpus:\n",
    "        tagged_sentence = nltk.pos_tag(sentence)\n",
    "\n",
    "        # Iterate over tagged words in the sentence\n",
    "        for i in range(len(tagged_sentence) - 1):\n",
    "            current_word, current_pos = tagged_sentence[i]\n",
    "            next_word, next_pos = tagged_sentence[i + 1]\n",
    "\n",
    "            # If the current POS is an adjective and the next POS is a noun\n",
    "            if current_pos.startswith('JJ') and next_pos.startswith('NN'):\n",
    "                if (current_word, next_word) in adj_noun_pairs:\n",
    "                    adj_noun_pairs[(current_word, next_word)] += 1\n",
    "                else:\n",
    "                    adj_noun_pairs[(current_word, next_word)] = 1\n",
    "\n",
    "            # If the current POS is a noun and the next POS is an adjective\n",
    "            elif current_pos.startswith('NN') and next_pos.startswith('JJ'):\n",
    "                if (current_word, next_word) in noun_adj_pairs:\n",
    "                    noun_adj_pairs[(current_word, next_word)] += 1\n",
    "                else:\n",
    "                    noun_adj_pairs[(current_word, next_word)] = 1\n",
    "\n",
    "    # Find the most common adjective-noun pairs\n",
    "    top_adj_noun_pairs = sorted(adj_noun_pairs.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "    # Find the most common noun-adjective pairs\n",
    "    top_noun_adj_pairs = sorted(noun_adj_pairs.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "    return top_adj_noun_pairs, top_noun_adj_pairs\n",
    "\n",
    "# Analyze Context \n",
    "top_adj_noun_pairs, top_noun_adj_pairs = find_common_pos_context(brown.sents())\n",
    "\n",
    "print(\"Top Adjective-Noun Pairs:\")\n",
    "for pair, count in top_adj_noun_pairs:\n",
    "    print(f\"{pair}: {count}\")\n",
    "\n",
    "print(\"\\nTop Noun-Adjective Pairs:\")\n",
    "for pair, count in top_noun_adj_pairs:\n",
    "    print(f\"{pair}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The analysis reveals the most common adjective-noun pairs and noun-adjective pairs found in the corpus.\n",
    "- Understanding the context of POS tags can enhance natural language understanding systems by providing insights into the syntactic patterns and relationships between words in text.\n",
    "- For example, identifying common adjective-noun pairs can help in tasks such as sentiment analysis or descriptive text generation, where adjectives often provide additional information about nouns.\n",
    "- Similarly, recognizing common noun-adjective pairs can aid in tasks like topic modeling or text summarization, where nouns represent key entities or concepts and adjectives provide attributes or characteristics.\n",
    "- By analyzing the context of POS tags, NLP systems can better comprehend the semantics and structure of text, leading to more accurate and nuanced language processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]\n"
     ]
    }
   ],
   "source": [
    "print(brown.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
